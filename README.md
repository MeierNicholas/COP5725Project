# COP5725Project

## Project Description 
- This is a modified implementation of the AIQL query system. This project accepts multievent, dependency, and anomaly queries, and converts them into SQL queries. These queries are scheduled based on their respective pruning power, and executed on the PostgreSQL database with help from the psycopg Python library. 

## Dependencies
This project requires several Python libraries in order to function properly. These libraries include:
- psycopg2 (version 2.8.6)
- nltk (version 3.5)
- prettytable (version 2.1.0)
- antlr4 (version 4.9.2)

<em> Note: nltk will require the punkt download. This can be accomplished by spawning a python3 terminal, and entering $import nltk $nltk.download('punkt') </em>

## Included Files
- queryengine.py
	- This is the main project file. This file contains all of the logic to take advantage of ANTLR4's parser, lexer, and listener to analyze AIQL queries and convert them to SQL queries. 
	These queries are then sent to the PostgreSQL database running on the system, using the psycopg library.
- aiql.g4
	- This is our grammar developed for use with ANTLR4. This grammar accepts multievent, dependency, and anomaly queries, as defined in the originally published AIQL paper. Examples of these queries can be found at the bottom of this README.
- The following files are generated as a result of running ANTLR4 on our grammar file, aiql.g4:
	- aiqlLexer.py
		- The lexer is a recognizer that draws input symbols from a character stream. [https://www.antlr.org/api/Java/org/antlr/v4/runtime/Lexer.html]
	- aiqlParser.py
		- The parser recognizes contextual orderings of tokens, as dictated by the parsing rules in the grammar.
	- aiqlListener.py
		- This is a base listener class that we inherit from in our custom Listener class, extendedListener, which is defined within the queryengine.py file.
	- \*.interp
		- The files with the .interp extension are used by IDEs for debugging grammars. These are not necessary for our program.
	- \*.tokens
		- The files with the .tokens extension contain lists of token names and their numeric assignment, which is generated by ANTLR. These files are used by the lexer.
- 250linesHost.csv (Subset of host logs used for testing, provided by LANL at https://csr.lanl.gov/data/2017/)
- 250linesNetwork.csv (Subset of network logs used for testing, provided by LANL at https://csr.lanl.gov/data/2017/)